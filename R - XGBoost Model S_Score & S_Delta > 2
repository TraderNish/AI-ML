# Set the directory and path right
getwd()
setwd("C:/Users/Nishant/Desktop/S_Score And S_Delta")

# Load the dataset from csv file
df = read.csv("filename.csv")

# Import the readyxl, tidyverse, xgboost, and caret packages
library(readyxl)
library(tidyverse)
library(xgboost)
library(caret)
library(dplyr)

# Using the dplyr package, let's take a subset of df:
df1 = df %>% select(raw_s, raw_s_mean, s, s_mean, s_delta, sv_vol)

# For reproducibility, set the seed
set.seed(123)

# Create index for testing and training data
inTrain = createDataPartition(y = df1$return_at_t_plus10, p = 0.8, list = FALSE)

# Subset data to training
training = df1[inTrain, ]

# Subset the rest to test
testing = df1[-inTrain, ]

# Convert the training and testing sets into DMatrixes:
# DMatrix is the recommended class in xgboost
X_train = xgb.DMatrix(as.matrix(training %>% select (-return_at_t_plus10)))
y_train = training$return_at_t_plus10
X_train = xgb.DMatrix(as.matrix(testing %>% select (-return_at_t_plus10)))
y_test = testing$return_at_t_plus10

# Specify cross-validation method and number of folds
# Also enable parallel computation

xgb_control = trainControl(
      method = "cv",
      number = 5,
      allowParallel = TRUE,
      verboseIter = TRUE, 
      returnData = FALSE
)

# This is the grid space to search for the best hyperparameter

xgbGrid = expand.grid(
      nrounds = c(100, 250, 500),
      colsample_bytree = seq(0.5, 0.9, length.out =5),
      # the values below are default values in the sklearn-api
      eta = c(0.1, 0.25, 0.5),
      gamma = 0,
      min_child_weight =1,
      subsample =1
      
)

# Finally, train your model

set.seed(0)
xgb_model = train( X_train, y_train, trControl = xgb_trcontrol, tuneGrid = xgbGrid, method = "xgbTree")

# Best values for hyperparameter
xgb_model$bestTune

# nrounds max_depth eta gamma colsample_bytree  min_child_weight  subsample
# 100     4         0.1  0    0.6               1                 1

# Model evaluation
predicted = predict(xgb_model, X_test)
residuals = y_test - predicted
RMSE = sqrt(mean(residuals^2))
cat("The root mean square error of the test data is ", round(RMSE, 3), '\n')

y_test_mean = mean(y_test)

# Calculate total sum of squares
tss = sum(y_test - y_test_mean^2)

# Calculte residual sum of squares
rss = sum(residuals^2)

# Calculate R-squared
rsq = 1 - (rss/tss)
cat('The R-square of the test data is ', round(rsq, 3), '\n')
