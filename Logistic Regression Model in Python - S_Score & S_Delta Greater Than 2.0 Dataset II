@author Nishant

# Import necessary modules

from sklearn.linear_model import LinearRegression
from sklearn import linear_model
from sklearn.model_selection import train_test_split
import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm


"""
Load 1 year dtaa where S_Score > 2.0 and S_Delta > 2.0 for various frequencies and try to find out which independent variable has related with the
response variable

Independent variables = [['raw_s', 's_delta', 's_score']]

Response variable = [return_at_t_plus10]

"""

print("Current Working Directory ", os.getcwd())

df = pd.read_csv('S_Score And S_Delta Greater Than 2.csv')

"""
Now, we will preprocess the data by standardizing it. 

# Scale: The scale transform calculates the standard deviation for an attribute and divides each value by that standard deviation.
# Center: The center transform calculates the mean for an attribute and subtracts it from each value. 
# Standardize: Combining the scale and center transform will standardize your data. Attributes will have a mean value of 0 and a standard deviation of 1.

"""

# normalized_df = (df - df.mean())/ dt.std()

"""
Let's treat this as a classification problem. For that, let's create a function to create a new column which can be used in the classification algorithm.
The column will be 1 if response variable return_at_t_plus10 is greater than return_at_t_plus1 or else 0

if price_at_t_plus10 > price_at_t:
  class = 1
Else class = 0

"""

def f(df):
  if (df.price_at_t_plus10 > df.price_at_t):
    val = 1
  else:
    val = 0
  return val
  
df['class'] = df.apply(f, axis =1)

"""
We can build a logistic regression model using the module linear_model from sklearn. First, you create a logistic regression model using the 
LogisticRegression() method:

Logreg = Linear_model.LogisticRegression()

Next, you need to feed data to the Logistic regession model, so that it can be fit. X contains the predictive variables, where y has the target. 

Independent variables = X = df[['raw_s', 's_delta', 's_score']]

Response variable = y = df[[return_at_t_plus10]]

Logred.fit(X, y)

"""

# import linear_model from sklearn
from sklearn import linear_model

# Create a dataframe X that only contains the candidate predictors 

# Create arrays for features and target variables

y = df['return_at_t_plus10'].values

x = [['raw_s', 's_delta', 's_score']].values

# Create training and testing sets
# we will use common split 70-30
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)

# validate set shapes 
print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)

# Import the necessary modules
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report

# Create a logistic regression model logreg and fit it to the data.
logreg = linear_model.LogisticRegression()
logreg.fit(X_train, y_train)

# Predict on the test data: y_pred
y_pred = reg_all.predict(X_test)

# Compute and print the confusion matrix and classification report
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

predictors = ['raw_s', 'raw_s_mean', 'raw_score', 's_mean']

X = df[predictors]
y = df[['class']]

# Assign the coefficients to a list coef

coef = logreg.coef_
for p,c in zip(predictors, list(coef[0])):
  print(p + '\t' + str(c))
  
# Assign the intercept to the variable intercept
intercept = logreg.intercept_
print(intercept)

"""
Classification reports and confusion matrices are great methods to quantitatively evaluate model performance, while ROC curves provide a way to
visually evaluate models. Most classifiers in scikit-learn have .predict_proba() method which returns the probability of a given sample
being in a particular class

"""

# Import necessary modules
from sklearn.metrics import roc_curve

# compute predicted probabilities" y_pred_prob
y_pred_prob = logreg.predict_proba(X_test)[:, 1]

# Generate ROC curve values: fpr, tpr, thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)

# plot ROC curve
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()

"""
AUC Score:
  There are a number of different methods you can use to evaluate your model's performance. AUC score is one such method which gives you an idea
  whether your model is better than the rangom guessing. If the AUC is greater than 0.5, the model is better than random guessing. 
  
"""

# Import necessary modules
from sklearn.model_selection import cross_val_score
from sklearn.metrics import roc_auc_score

"""
Using the logreg classifier, which has been fit to the training data, compute the predicted proababilities of the labels of the test set X_test
and compute predicted probabilities: y_pred_prob

"""

y_pred_prob = logreg.predict_proba(X_test)[:, 1]

# Compute and print AUC Score
print("AUC: {}".format(roc_auc_score(y_test, y_pred_prob)))

"""
Now, we will compute the AUC scores by performing 5 fold cross validation. We will use the cross_val_score() function and specify the scoring
parameter to be 'roc_auc'. 

Also, compute cross-validated AUC scores: cv_auc

"""
cv_auc = cross_val_score(logreg, X, y, cv = 5, scoring= 'roc_auc')

# print list of AUC scores
print("AUC scores computed using 5-fold cross-validation: {}".format(cv_auc))

"""
Hyperparameter Tuning:
  When we do the regression, we chose the parameters for the model that fits the data best. These parameters which need to be specified before fitting
  the model are called hyperparameters. In other words, these are the parameters which can't be explicitly learned by fitting the model. 
  
 SearchCV can help us try different combination of hyperparameters on the data to find the best combination. 

"""

# Import necessary modules
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

"""
In addition to C, logistic regression has a penalty hyperparameter which specifies whether to use 'l1' or 'l2' regularization. 

"""

# Create the hyperparameter grid
c_space = np.logspace(-5, 8, 15, 30)
param_grid = {'C': c_space, 'penalty':['L1', 'L2']}

# Instantiate the logistic regression classifier: logreg
logreg = LogisticRegression()

# Create training and testing sets
# we will use common split 70-30
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)

# Instantiate the GridSearchCV object: logreg_cv
logreg_cv = GridSearchCV(logreg, param_grid, cv = 5)

# Fit it to the training data
logreg_cv.fit(X_train, y_train)

# Print the optimal parameters and best score
print("Tuned Logistic Regression Parameter: {}".format(logreg_cv.best_params_))
print("Tuned Logistic Regression Parameter: {}".format(logreg_cv.best_score_))
