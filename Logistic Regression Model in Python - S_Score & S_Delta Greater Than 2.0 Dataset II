@author Nishant

# Import necessary modules

from sklearn.linear_model import LinearRegression
from sklearn import linear_model
from sklearn.model_selection import train_test_split
import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm


"""
Load 1 year dtaa where S_Score > 2.0 and S_Delta > 2.0 for various frequencies and try to find out which independent variable has related with the
response variable

Independent variables = [['raw_s', 's_delta', 's_score']]

Response variable = [return_at_t_plus10]

"""

print("Current Working Directory ", os.getcwd())

df = pd.read_csv('S_Score And S_Delta Greater Than 2.csv')

"""
Now, we will preprocess the data by standardizing it. 

# Scale: The scale transform calculates the standard deviation for an attribute and divides each value by that standard deviation.
# Center: The center transform calculates the mean for an attribute and subtracts it from each value. 
# Standardize: Combining the scale and center transform will standardize your data. Attributes will have a mean value of 0 and a standard deviation of 1.

"""

# normalized_df = (df - df.mean())/ dt.std()

"""
Let's treat this as a classification problem. For that, let's create a function to create a new column which can be used in the classification algorithm.
The column will be 1 if response variable return_at_t_plus10 is greater than return_at_t_plus1 or else 0

if price_at_t_plus10 > price_at_t:
  class = 1
Else class = 0

"""

def f(df):
  if (df.price_at_t_plus10 > df.price_at_t):
    val = 1
  else:
    val = 0
  return val
  
df['class'] = df.apply(f, axis =1)

"""
We can build a logistic regression model using the module linear_model from sklearn. First, you create a logistic regression model using the 
LogisticRegression() method:

Logreg = Linear_model.LogisticRegression()

Next, you need to feed data to the Logistic regession model, so that it can be fit. X contains the predictive variables, where y has the target. 

Independent variables = X = df[['raw_s', 's_delta', 's_score']]

Response variable = y = df[[return_at_t_plus10]]

Logred.fit(X, y)

"""

# import linear_model from sklearn
from sklearn import linear_model

# Create a dataframe X that only contains the candidate predictors 

# Create arrays for features and target variables

y = df['return_at_t_plus10'].values

x = [['raw_s', 's_delta', 's_score']].values

# Create training and testing sets
# we will use common split 70-30
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)

# validate set shapes 
print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)

# Import the necessary modules
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report

# Create a logistic regression model logreg and fit it to the data.
logreg = linear_model.LogisticRegression()
logreg.fit(X_train, y_train)

# Predict on the test data: y_pred
y_pred = reg_all.predict(X_test)

# Compute and print the confusion matrix and classification report
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

predictors = ['raw_s', 'raw_s_mean', 'raw_score', 's_mean']

X = df[predictors]
y = df[['class']]

# Assign the coefficients to a list coef

coef = logreg.coef_
for p,c in zip(predictors, list(coef[0])):
  print(p + '\t' + str(c))
  
# Assign the intercept to the variable intercept
intercept = logreg.intercept_
print(intercept)

"""
Classification reports and confusion matrices are great methods to quantitatively evaluate model performance, while ROC curves provide a way to
visually evaluate models. Most classifiers in scikit-learn have .predict_proba() method which returns the probability of a given sample
being in a particular class

"""

# Import necessary modules
from sklearn.metrics import roc_curve

# compute predicted probabilities" y_pred_prob
y_pred_prob = logreg.predict_proba(X_test)[:, 1]

# Generate ROC curve values: fpr, tpr, thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)

# plot ROC curve
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()


